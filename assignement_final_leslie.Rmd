---
title: "assignement2"
author: "Lilach Herzog & Leslie Cohen"
date: "13 5 2022"
output: 
  word_document: 
    toc: yes
    toc_depth: 4
  pdf_document: 
    toc_depth: 1
    fig_caption: yes
    number_sections: yes
    fig_height: 3
editor_options: 
  chunk_output_Class: inline
---

Our whole project and code can be found on github at https://github.com/LeslieLebon/assignment-2.git

Our objective in this project was to analyze the “wheat-glaucoma” dataset (where the 'Class' of the seed is the column used for labeling and classifying) using two classifier models that we built. We decided on using the KNN algorithm and the Decision Tree (DT) algorithm.

# preproccessing

## Upload data and libraries

```{r, message=FALSE, warning=FALSE}
library(gmodels)
library(C50)
library(class) 
library(tidymodels) # for the rsample package, along with the rest of tidymodels
library(ROCR)
library(reshape2)
library(ggpmisc)
library(ggplot2)
library(gridExtra)
library(pROC)
library(ggfortify)
library(corrplot)
library(dplyr)


glaucoma <- read.csv("GlaucomaM.csv")# read data
set.seed(1234)#to initialize a pseudo random number generator. 
```



## split into training and test sets
### initial look at the data

We know the class ‘Class’ is the column (label) to classify according to. We took a quick look at the data as a whole, and specifically the 'Class' column. In order to further understand the data and be able to work with it we also used the "table" function. this function builds a contingency table of the counts at each combination of factor levels- we used it for the 'Class'.
```{r, message=FALSE, warning=FALSE}
str(glaucoma) #quick look at the data as a whole
table(glaucoma$Class) # quick look specifically at the 'Class' column
table(normal$Class)
```
The column we want to classify is 'Class'. There are 3 Classs of glaucoma found in in the column 'Class': 1, 2 and 3 (We will sometimes refer to them as Class_1, Class_2 and Class_3, to make it easier to understand and differentiate them from numbers that represent other things). 
We can see the Class has 66 times Class_1, 68 times Class_2, and 65 times Class_3, about a third of each Class.


# EDA analysis

Results obtained with corrplot:
Positive correlations are displayed in a blue scale while negative correlations are displayed in a red scale.
we can observe 8 clusters of features.
Results obtained with heatmap:
we can observe one big cluster that could be divided in 2 and 2 others clusters of features.

>>>>>>>>>>>>>>>>>>>>It means that ??? we should delete features that are correlated?????? what do you think Lilach?

```{r, message=FALSE, warning=FALSE}

# Preform PCA on our data

gl.pca <- prcomp(glaucoma[,1:62],
                   center = TRUE,
                   scale. = TRUE)
  
# summary of the 
# prcomp object
summary(gl.pca)
gl_pca_plot <- autoplot(gl.pca,
                          data = glaucoma,
                          colour = 'Class')
  



gl_pca_plot
```


In the PCA, we can observe that most of glaucoma patients and normal patients are clustered in 2 groups, but some of them are mixed, probably to the fact that many features correlate.

Let's try to observe the different pvalues of correlation, to determine which feature are correlated.

We will try to see if we can observe any correlation between features.

```{r, message=FALSE, warning=FALSE}
#calculation of correlation, using pearson correlation
summary(glaucoma)
gl.cor = cor(glaucoma[,c(1:62)], method = c("pearson"))

corrplot(gl.cor)

palette = colorRampPalette(c("green", "white", "red")) (20)
heatmap(x = gl.cor, col = palette, symm = TRUE)

```


```{r, message=FALSE, warning=FALSE}
library("Hmisc")
#This generates one table of correlation coefficients (the correlation matrix) and another table of the p-values. By default, the correlations and p-values #are stored in an object of class type rcorr. To extract the values from this object into a useable data structure, you can use the following syntax:
gl.rcorr = rcorr(as.matrix(glaucoma[,c(1:62)]))
gl.rcorr
gl.coeff = gl.rcorr$r

cor_matrix_rm <- gl.cor                  # Modify correlation matrix
cor_matrix_rm[upper.tri(cor_matrix_rm)] <- 0
diag(cor_matrix_rm) <- 0
cor_matrix_rm

data<-glaucoma[,c(1:62)]
data_new <- data[ , !apply(cor_matrix_rm,    # Remove highly correlated variables
                           2,
                           function(x) any(x > 0.8))]
head(data_new)


gl.cor2 = cor(data_new, method = c("pearson"))
corrplot(gl.cor2)
heatmap(x = gl.cor2, col = palette, symm = TRUE)
colSums(glaucoma[,c(1:62)] != 0)


```



```{r, message=FALSE, warning=FALSE}

########
# Preform PCA on our new data

gl.pca2 <- prcomp(data_new,
                   center = TRUE,
                   scale. = TRUE)#play with options
  
# summary of the 
# prcomp object
summary(gl.pca2)
gl_pca_plot2 <- autoplot(gl.pca2,
                          data = glaucoma,
                          colour = 'Class')
  



gl_pca_plot2
gl_pca_plot

```



>>> should we delete some features with a high correlation?PCA is not enough to classify patients.


Before starting on teaching the algorithm, we converted the 'Class' column to a factor, as that is what is required by the C50 package.
```{r, message=FALSE, warning=FALSE}
glaucoma$Class<-as.factor(glaucoma$Class)
```
Since the whole table is sorted according to the 'Class' column, and we want to work randomly, we will shuffle the whole table
```{r, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
glaucoma <- glaucoma[sample(nrow(glaucoma)),]
str(glaucoma) #look at the data again to make sure it's shuffled
```

### Splitting
```{r, message=FALSE, warning=FALSE}
length_of_training_set <-round(0.8*(nrow(glaucoma)),0)
train_set <- glaucoma[1:length_of_training_set, ]
test_set <- glaucoma[(length_of_training_set+1):nrow(glaucoma), ]
train_set_Classs <-train_set[, 8]
test_set_Classs <-test_set[, 8]
prop.table(table(train_set$Class))
```
Since we know that there are about a third of each Class in the data set, we wanted to be sure that the distribution is as we defined (about 1/3 of each Class in of both training and test sets)
